{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name, email and UFID.\n",
    "Please do not modify instruction cells or any cells with automated tests (marked with `[ASSERTS]`). Note: you can add new cells if you need them, but answers must be in the cells with `YOUR CODE HERE` or \"YOUR ANSWER HERE\" comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d32c3222b2442d52b065e77cd55ac2f",
     "grade": false,
     "grade_id": "homework-preamble",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Homework 2: Regression and Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5658c9a4ed21f362746fdaeb7fb21351",
     "grade": false,
     "grade_id": "preamble-name",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Preamble: Write your Name, Email and UFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cac6c2934a26e1ec9725344dae3cb163",
     "grade": false,
     "grade_id": "name-email-ufid",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homework 2 -- name: Tre' Jeter, email: t.jeter@ufl.edu, UFID: 19469876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NAME = 'Tre\\' Jeter'\n",
    "EMAIL = 't.jeter@ufl.edu'\n",
    "UFID = 19469876\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "print('Homework 2 -- name: {}, email: {}, UFID: {}\\n'.format(NAME, EMAIL, UFID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c41a13a5f6e2fa1b47621d28e926c2cf",
     "grade": true,
     "grade_id": "name-email-ufid-asserts",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check that your name, email, and UFID is filled in.\"\"\"\n",
    "assert NAME != '' and NAME != 'Your name here.' and len(NAME) > 3\n",
    "assert EMAIL != '' and EMAIL != 'Your email here.' and len(EMAIL) > 7\n",
    "assert type(UFID) == int and UFID != 12345678 and UFID >= 10000000 and UFID <= 99999999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b4f30c4bbc2f9927b1410eeb1f001b3",
     "grade": false,
     "grade_id": "preamble-academic-integrity",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Academic Integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99184dabc791053131230787b9f498b8",
     "grade": false,
     "grade_id": "preamble-academic-integrity-2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <span style=\"color:red;\">This is an individual assignment. Academic integrity violations (i.e., cheating, plagiarism) will be reported to SCCR!</span><br/>\n",
    "#### The official CISE policy recommended for such offenses is a course grade of E. Additional sanctions may be imposed by SCCR such as marks on your permanent educational transcripts, dismissal or expulsion.\n",
    "#### Reminder of the Honor Pledge: On all work submitted for credit by Students at the University of Florida, the following pledge is either required or implied: *\"On my honor, I have neither given nor received unauthorized aid in doing this assignment.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d8d2452e1d9f6d547eae6447b7ca369",
     "grade": false,
     "grade_id": "cell-preamble-academic-integrity-3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Acknowledgement: Do you acknowledge and understand the academic integrity warning above? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89bc9ed2e09cb9069b92dc24a3bc081a",
     "grade": false,
     "grade_id": "academic-integrity",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "academic_integrity_acknowledgement = True\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7d6eb103ab3a60e964c163468d9aa7a",
     "grade": true,
     "grade_id": "academic-integrity-assert",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check that you acknowledge the academic integrity warning, you understand it and have been reminded of the UF Honor Pledge.\"\"\"\n",
    "assert academic_integrity_acknowledgement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f73a6c8f764fdac6667f0157a544866",
     "grade": false,
     "grade_id": "task1-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "# [Task 1] (20 points) Loading and preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd89203347fe0a5164b6775ddd443acb",
     "grade": false,
     "grade_id": "task1-instructb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 1] We will use the Bike Sharing dataset (hourly). A version of this dataset is included in the homework handout archive.\n",
    "### This dataset contains features of users bike sharing/rental on an hourly basis.\n",
    "### The task is to predict how many users are sharing/renting a bike.\n",
    "### In this task you will load the data and preprocess it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40e0c6343e3d6ae8ef5568125e9de64f",
     "grade": false,
     "grade_id": "task1-instructc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### The following cell's code (import statements etc.) is provided for you and you should not need to change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "119d3a62a34e7425f288493659994237",
     "grade": false,
     "grade_id": "task1-code",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "### Python version: 3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]\n",
      "### NumPy version: 1.20.3\n",
      "### Scikit-learn version: 1.4.0\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Load packages we need\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "# Let's check our software versions\n",
    "print('------------')\n",
    "print('### Python version: ' + __import__('sys').version)\n",
    "print('### NumPy version: ' + np.__version__)\n",
    "print('### Scikit-learn version: ' + sklearn.__version__)\n",
    "print('------------')\n",
    "\n",
    "def var_exists(var_name):\n",
    "    return (var_name in globals() or var_name in locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5cc6d3b909b447a027649ca1d83883d9",
     "grade": false,
     "grade_id": "seed_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### This is the seed we will use, do not change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d04202483cecc7aa53f8ad98656ef967",
     "grade": false,
     "grade_id": "setting_seed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# set the seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "prop_vec = [16, 2, 2] # proportions for train - val - test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d746a78509c270bb1f51eff6a455a1f6",
     "grade": true,
     "grade_id": "seed_checking",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check seed. \"\"\"\n",
    "assert seed == 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b26690ee65de9a82553bc05a151c027e",
     "grade": false,
     "grade_id": "task1-instructd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loading data (set the path correctly so it runs on your machine --- don't submit the data file with your notebook).\n",
    "#### Note: this dataset has missing values (artificially introduced), which you'll need to fill in before you can train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "424a20cc93e7cd774f4c8c7ca4e10b8e",
     "grade": false,
     "grade_id": "task1-loaddata",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Fill in the path to the directory where 'bikesharehour.csv.gz' is located.\n",
    "\"\"\"\n",
    "# data_root = '<relative or absolute path to directory>' #put the path here\n",
    "data_root = 'data/'\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f165779998390d2ddff4aea0e0ac8453",
     "grade": true,
     "grade_id": "task1-loaddata-test",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   season      16320 non-null  float64\n",
      " 1   year        16231 non-null  float64\n",
      " 2   month       16304 non-null  float64\n",
      " 3   hour        16254 non-null  float64\n",
      " 4   holiday     16277 non-null  float64\n",
      " 5   weekday     16282 non-null  float64\n",
      " 6   workingday  16297 non-null  float64\n",
      " 7   weathersit  16324 non-null  float64\n",
      " 8   temp        16242 non-null  float64\n",
      " 9   atemp       16271 non-null  float64\n",
      " 10  hum         16252 non-null  float64\n",
      " 11  windspeed   16281 non-null  float64\n",
      " 12  registered  16244 non-null  float64\n",
      " 13  nsqrtc      16263 non-null  float64\n",
      " 14  count       17379 non-null  int64  \n",
      "dtypes: float64(14), int64(1)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_fp = os.path.join(data_root, 'bikesharehour.csv.gz')\n",
    "assert os.path.exists(dataset_fp), 'Dataset not found ({})!'.format(dataset_fp)\n",
    "df = pd.read_csv(dataset_fp, compression='gzip', header=0, na_values='?')\n",
    "\n",
    "# Check that we loaded the data as expected\n",
    "df_expected_shape = (17379, 15)\n",
    "assert df.shape == df_expected_shape, 'Unexpected shape of df!'\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2658b88a5895c78122a30edae6ae60e1",
     "grade": false,
     "grade_id": "task1a_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 1a] (5 points) Show the first 8 rows of the dataframe df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c184f6d42bf2f1fd7c9d09dcb513c987",
     "grade": false,
     "grade_id": "task1a_answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>registered</th>\n",
       "      <th>nsqrtc</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  year  month  hour  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0     1.0   0.0    NaN   0.0      0.0      6.0         0.0         1.0   NaN   \n",
       "1     1.0   0.0    NaN   1.0      0.0      6.0         0.0         1.0   NaN   \n",
       "2     1.0   0.0    1.0   2.0      0.0      6.0         0.0         1.0   0.0   \n",
       "3     1.0   0.0    1.0   3.0      0.0      6.0         0.0         1.0   0.0   \n",
       "4     1.0   0.0    1.0   4.0      0.0      6.0         0.0         1.0   0.0   \n",
       "5     1.0   0.0    1.0   5.0      0.0      6.0         0.0         2.0   0.0   \n",
       "6     1.0   0.0    1.0   6.0      0.0      6.0         0.0         1.0   0.0   \n",
       "7     1.0   0.0    1.0   7.0      0.0      6.0         0.0         1.0   0.0   \n",
       "\n",
       "   atemp  hum  windspeed  registered  nsqrtc  count  \n",
       "0    0.0  0.0        0.0        13.0    -5.0     16  \n",
       "1    0.0  0.0        0.0        32.0    -8.0     40  \n",
       "2    0.0  0.0        0.0        27.0    -7.0     32  \n",
       "3    0.0  0.0        0.0        10.0    -5.0     13  \n",
       "4    0.0  0.0        0.0         1.0     0.0      1  \n",
       "5    0.0  0.0        1.0         1.0     0.0      1  \n",
       "6    0.0  0.0        0.0         0.0     4.0      2  \n",
       "7    NaN  0.0        0.0         2.0    -3.0      3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Put your code here.\n",
    "\"\"\"\n",
    "## what does the data look like?\n",
    "# YOUR CODE HERE\n",
    "df.head(8)\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "207850a57807f6a443236f5a23ef531e",
     "grade": true,
     "grade_id": "task1-features",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['season', 'year', 'month', 'hour', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'registered', 'nsqrtc'] --- target: count\n"
     ]
    }
   ],
   "source": [
    "# grab all the data as a numpy matrix\n",
    "all_xy = df.to_numpy()\n",
    "\n",
    "col_names = [c for c in df.columns]\n",
    "features = col_names[:-1]\n",
    "target = col_names[-1]\n",
    "\n",
    "# what are the features and what is the target?\n",
    "print('features: {} --- target: {}'.format(features, target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c77734990f89e7420bea2fd71508fcc",
     "grade": false,
     "grade_id": "task1b-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 1b] (5 points) Answer the following questions by setting variables (hardcoding or computing the answer) from 'all_xy'. (1) If we do supervise learning to predict 'count' based on our features is this classification or regression? (Set the corresponding variable to True.) (2) How many NaNs are there in columns 'holiday','temp', and 'count'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e10a22f5cd4a405b28c06b0d1bafc2a",
     "grade": false,
     "grade_id": "task1b-code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here and set the variables appropriately.\n",
    "\"\"\"\n",
    "classification = False\n",
    "regression = True\n",
    "\n",
    "h_NaNs = df['holiday'].isna().sum()\n",
    "t_NaNs = df['temp'].isna().sum()\n",
    "cnt_NaNs = df['count'].isna().sum()\n",
    "\n",
    "holiday_NaNs = h_NaNs\n",
    "temp_NaNs = t_NaNs\n",
    "count_NaNs = cnt_NaNs\n",
    "\n",
    "# holiday_NaNs, temp_NaNs, count_NaNs\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc7d99202916a313b25fcfe853eabb82",
     "grade": true,
     "grade_id": "task1b_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check 1b completed. \"\"\"\n",
    "\n",
    "assert var_exists('classification') and var_exists('regression') and classification != regression\n",
    "assert var_exists('holiday_NaNs') and holiday_NaNs >= 0\n",
    "assert var_exists('temp_NaNs') and temp_NaNs >= 0\n",
    "assert var_exists('count_NaNs') and count_NaNs >= 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4c3f1a8772ba51267b07033f0557d23",
     "grade": false,
     "grade_id": "task1c_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 1c] (5 points) Let's impute the missing values! Use Scikit-learn's SimpleImputer to replace all NaNs in 'all_xy' with the *most frequent* value in each column. Use copy=True and store the results in 'all_xy_noNaNs' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ed4013643fc31a30fb6b4c395a42fa3",
     "grade": false,
     "grade_id": "task1c_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here (~2-3 lines).\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputer = SimpleImputer(copy=True)\n",
    "all_xy_noNaNs = imputer.fit_transform(all_xy)\n",
    "\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4efd8da58007234bfbad9d825036ade0",
     "grade": true,
     "grade_id": "task1c_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check 1c completed. \"\"\"\n",
    "\n",
    "assert var_exists('all_xy_noNaNs') and all_xy_noNaNs.shape == df_expected_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1024eb6bf3e5eb85b038955feda0cbdc",
     "grade": false,
     "grade_id": "task1d-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 1d] (5 points) Min-max normalize the features (to [0,1] range) using sklearn's MinMaxScaler. Store the results into 'scaled_all_x'. Then split the data into train, val, test according to the proportion in prop_vec using sklearn's train_test split. Store the results into 'train_x', 'train_y', 'test_x', 'test_y', 'val_x', 'val_y'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33549a9e16d2ce1ac32610f23d0c8d16",
     "grade": false,
     "grade_id": "task1d_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13903, 14), (13903,), (1738, 14), (1738,), (1738, 14), (1738,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Put your code here (~5-7 lines).\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_all_x = scaler.fit_transform(all_xy_noNaNs[:,:-1])\n",
    "\n",
    "target_value = all_xy_noNaNs[:,-1]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(scaled_all_x, target_value, test_size=(prop_vec[1] + prop_vec[2]) / (prop_vec[0] + prop_vec[1] + prop_vec[2]), random_state=seed)\n",
    "test_x, val_x, test_y, val_y = train_test_split(test_x, test_y, test_size=(prop_vec[1] + prop_vec[2]) / (prop_vec[0]/prop_vec[1]), random_state=seed)\n",
    "\n",
    "train_x.shape, train_y.shape, val_x.shape, val_y.shape, test_x.shape, test_y.shape\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f4391b903af2254d5c08592beb7f674",
     "grade": true,
     "grade_id": "task1d_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check split for task 1d. \"\"\"\n",
    "assert var_exists('scaled_all_x')\n",
    "assert var_exists('train_x') and var_exists('train_y') and train_x.shape[0] == train_y.shape[0]\n",
    "assert var_exists('val_x') and var_exists('val_y') and val_x.shape[0] == val_y.shape[0]\n",
    "assert var_exists('test_x') and var_exists('test_y') and test_x.shape[0] == test_y.shape[0]\n",
    "assert train_x.shape == (13903, 14) and val_x.shape == (1738, 14) and test_x.shape == (1738, 14)\n",
    "assert np.amin(train_x) >= 0.0 and np.amax(train_x) <= 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d244ec65844cdeb839f49b48a142b738",
     "grade": false,
     "grade_id": "task2_instructa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 2] (30 points) Evaluating and training linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "468d738a8668ff10566793c58904bae5",
     "grade": false,
     "grade_id": "task2a_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2a] (5 points) Fill in the code to calculate and return the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1d196c4244c95960b2734f67ab68df8",
     "grade": false,
     "grade_id": "task2a_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Fill in your code below (~5-7 lines).\n",
    "\"\"\"\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def r2_mse_mae_eval(model, tr_x, tr_y, v_x, v_y, pref='', verb=True):\n",
    "\n",
    "    \"\"\"Fill in your code below (~1-2 lines).\n",
    "    \"\"\"\n",
    "    # R^2 the coefficient of determination\n",
    "    # YOUR CODE HERE\n",
    "    train_r2 = r2_score(tr_y, model.predict(tr_x))\n",
    "    val_r2 = r2_score(v_y, model.predict(v_x))\n",
    "    # raise NotImplementedError()\n",
    "    \n",
    "    if verb:\n",
    "        print('{}Train R^2: {:.3f}, Val  R^2: {:.3f}'.format(pref, train_r2, val_r2))\n",
    "\n",
    "    train_pred = model.predict(tr_x)\n",
    "    val_pred = model.predict(v_x)\n",
    "\n",
    "    \"\"\"Fill in your code below (~1-2 lines).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    train_mse = mean_squared_error(tr_y, train_pred)\n",
    "    val_mse = mean_squared_error(v_y, val_pred)\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "    if verb:\n",
    "        print('{}Train MSE: {:.3f}, Val MSE: {:.3f}'.format(pref, train_mse, val_mse))\n",
    "\n",
    "    \"\"\"Fill in your code below (~1-2 lines).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    train_mae = mean_absolute_error(tr_y, train_pred)\n",
    "    val_mae = mean_absolute_error(v_y, val_pred)\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "    if verb:\n",
    "        print('{}Train MAE: {:.3f}, Val MAE: {:.3f}'.format(pref, train_mae, val_mae))\n",
    "\n",
    "    return train_r2, val_r2, train_mse, val_mse, train_mae, val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18b3441ddafcf1fd86c8562815958ce4",
     "grade": true,
     "grade_id": "task2a_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check split for task 2a. \"\"\"\n",
    "assert var_exists('r2_mse_mae_eval')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19220fc3ba3d815f8fbcb28390c0ccf7",
     "grade": false,
     "grade_id": "task2b-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2b] (5 points) Train a linear regression model using the default (hyper)parameters. Call the resulting trained model 'lrmodel'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5dfe0fdc4f5aeae197e64d44281a5e16",
     "grade": false,
     "grade_id": "task2b_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LinearRegression] Train R^2: 0.895, Val  R^2: 0.891\n",
      "[LinearRegression] Train MSE: 3483.086, Val MSE: 3244.993\n",
      "[LinearRegression] Train MAE: 34.013, Val MAE: 32.707\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Put your code here (~1-2 lines).\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "# YOUR CODE HERE\n",
    "lrmodel = LinearRegression().fit(train_x, train_y)\n",
    "# raise NotImplementedError()\n",
    "\n",
    "_ = r2_mse_mae_eval(lrmodel, train_x, train_y, val_x, val_y, pref='[{}] '.format(lrmodel.__class__.__name__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4ff682ab212149d93df0732df296ce5",
     "grade": false,
     "grade_id": "task2b-instruct2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2b] How good is that model? (A few sentences is fine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f28a10e885076e373cd3240aae6b68d",
     "grade": true,
     "grade_id": "cell-task2b_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer: \n",
    "# The r^2 value on both training and validation sets are both high which means the model\n",
    "# is generalizing to the target pretty well. However, the MSE and MAE values are extremely\n",
    "# high meaning that the model's predictive capabilities are not that good. MSE and MAE should\n",
    "# be smaller values so the fact that the reported values are really high means the accuracy of \n",
    "# this model is probably not that good. So, this model isn't that good in that regard.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c931713a37b5131c09838b45911da0e8",
     "grade": false,
     "grade_id": "task2c_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2c] (5 points) Fill in the code below to setup a grid search. Concatenate the train and val sets into 'search_x' and 'search_y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6adb5fda3e1a8a6253453ee906e3add6",
     "grade": false,
     "grade_id": "task2c_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## some code to do a grid search and automatically train & evaluate the model with the best hyperparams.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def do_grid_search(model, param_grid, x, y):\n",
    "    gs = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error')\n",
    "    gs_res = gs.fit(x, y)\n",
    "    return  gs_res.best_params_\n",
    "\n",
    "\n",
    "def search_train_eval(model, param_grid, tr_x=train_x, tr_y=train_y, v_x=val_x, v_y=val_y):\n",
    "\n",
    "    \"\"\"Put your code here (~2-3 lines). Concatenate the train and val sets into 'search_x' and 'search_y'.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    search_x = np.concatenate((train_x, val_x))\n",
    "    search_y = np.concatenate((train_y, val_y))\n",
    "    # raise NotImplementedError()\n",
    "    \n",
    "    hyperparams = do_grid_search(model, param_grid, search_x, search_y)\n",
    "    \n",
    "    class_obj = type(model)\n",
    "    m = class_obj(**hyperparams).fit(tr_x, tr_y)\n",
    "    \n",
    "    cn = str(class_obj).split(\"'\")[1]\n",
    "    cn = cn.split('.')[-1]\n",
    "    print('{}({})'.format(cn, hyperparams))\n",
    "\n",
    "    r2_mse_mae_eval(m, tr_x, tr_y, v_x, v_y, pref='\\t')\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48519e6f82d7736ba46225ca36362d92",
     "grade": true,
     "grade_id": "task2c_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 2c. \"\"\"\n",
    "assert var_exists('search_train_eval')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dd2d328fca71fef762e80afcb4c533e",
     "grade": false,
     "grade_id": "task2d_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2d] (10 points) Take a look at the code of search_train_eval() and do_grid_search(). Answer the following questions: \n",
    "### 1. Can you do LAD regression with sklearn? Why or why not? (Justify your answer.) Hint: take a look at the sklearn documentation and the course slides.\n",
    "### 2. Why is the scoring function for the grid search 'neg_mean_squared_error' (as opposed to 'mean_squared_error')? \n",
    "### 3. Why is it okay to do the search over search_x and search_y which are the concatenation of the train and 'validation sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72e30d480e9d39db7c1b99aa78c2dbc9",
     "grade": true,
     "grade_id": "task2d_answer",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "### Hint: take a look at the documentation of scikit-learn and think.\n",
    "## Answer: \n",
    "# (1) From the documentation,it seems that LADRegression cannot be done directly with sklearn \n",
    "# (i.e.,from sklearn.linear_model import LADRegression), but there are other ways to get similar results \n",
    "# such as using the HuberRegressor or SGDRegressor.\n",
    "# https://gurobi-optimization-gurobi-optimods.readthedocs-hosted.com/en/latest/mods/lad-regression.html\n",
    "# https://scikit-lego.netlify.app/linear-models.html#Least-Absolute-Deviation-Regression\n",
    "# https://stats.stackexchange.com/questions/376643/is-there-any-library-for-least-absolute-deviation-lad-regression-with-regulari#:~:text=If%20you%20use%20the%20SGDRegressor,to%20LAD%20with%20L2%20regularization.&text=QuantileRegressor%20in%20scikit%2Dlearn%20is,heavily%2C%20by%20default)%20regularized.\n",
    "# From the lecture slides, LADRegression is more robust to outliers, but mathematically less convenient to work with than OLS.\n",
    "\n",
    "# (2) The usual convention of sklearn is that higher scores means better performance.\n",
    "# Because MSE is a loss function, the lower the scores, the better the performance. Therefore,\n",
    "# by negating the MSE, we can ensure the score is truly maximized as sklearn intends while reporting\n",
    "# an accurate value.\n",
    "\n",
    "# (3) It's okay to search over search_x and search_y because the validation sets main purpose is for\n",
    "# hyperparamter tuning and model evaluation. Having it included in the search allows for \n",
    "# hyperparameter optimization. \n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64460c67c3a177ebf1ab32de263afbc6",
     "grade": false,
     "grade_id": "task2e_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 2e] (5 points) Write the code below to do a grid search on a LassoLars model. Call the resulting model 'lassolars_model'. Be sure to tune the regularization constant and 'fit_intercept'. Make sure training converges and that you set the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af01b53b3bacacf8b6212b96621717c2",
     "grade": false,
     "grade_id": "task2e_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 0.01, 'fit_intercept': True}\n",
      "LassoLars({'alpha': 0.01, 'fit_intercept': True})\n",
      "\tTrain R^2: 0.895, Val  R^2: 0.891\n",
      "\tTrain MSE: 3483.127, Val MSE: 3243.863\n",
      "\tTrain MAE: 33.991, Val MAE: 32.680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Put your code here (~2-3 lines).\n",
    "\"\"\"\n",
    "\n",
    "# CHECK AGAIN\n",
    "from sklearn.linear_model import LassoLars\n",
    "\n",
    "# YOUR CODE HERE\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1.0, 5.0, 10.0],\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "lassolars_model = LassoLars(random_state=seed)\n",
    "lassolars_hyperparams = do_grid_search(lassolars_model, param_grid, train_x, train_y)\n",
    "lassolars_model_best = LassoLars(**lassolars_hyperparams).fit(train_x, train_y)\n",
    "\n",
    "print(\"Best Hyperparameters:\", lassolars_hyperparams)\n",
    "search_train_eval(lassolars_model, param_grid, train_x, train_y, val_x, val_y)\n",
    "\n",
    "def isConverged(model):\n",
    "    return hasattr(model, 'coef_')\n",
    "\n",
    "isConverged(lassolars_model_best)\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4e8cf326726c6095e9cfb210218ede0",
     "grade": true,
     "grade_id": "task2e_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 2e. \"\"\"\n",
    "assert var_exists('lassolars_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad6f73eba9ec23c4ffb8c2f3c9b79b1a",
     "grade": false,
     "grade_id": "task3-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 3] (25 points) Let's train polynomial regression models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fb5dfae82b37f31d9212710d252b6cb",
     "grade": false,
     "grade_id": "task3a-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 3a] (15 points) Use PolynomialFeatures to create a version of the data with all features of degree 3. Follow the provided instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3de785d8bb3ca7ddc296eb8b7968897",
     "grade": false,
     "grade_id": "task3a-code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge w/o Polynomial Features:\n",
      "Ridge({})\n",
      "\tTrain R^2: 0.895, Val  R^2: 0.892\n",
      "\tTrain MSE: 3465.565, Val MSE: 3230.597\n",
      "\tTrain MAE: 33.753, Val MAE: 32.515\n",
      "\n",
      "Linear Regression w/ Polynomial Features:\n",
      "LinearRegression({})\n",
      "\tTrain R^2: 0.955, Val  R^2: 0.948\n",
      "\tTrain MSE: 1478.207, Val MSE: 1556.764\n",
      "\tTrain MAE: 17.189, Val MAE: 17.937\n",
      "\n",
      "Ridge w/ Polynomial Features:\n",
      "Ridge({'alpha': 1.0})\n",
      "\tTrain R^2: 0.951, Val  R^2: 0.945\n",
      "\tTrain MSE: 1627.915, Val MSE: 1640.276\n",
      "\tTrain MAE: 16.988, Val MAE: 16.902\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Ridge<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Ridge.html\">?<span>Documentation for Ridge</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Ridge()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Put your code here (~10-15 lines).\n",
    "    1. Use PolynomialFeatures to create a version of the data with all features of degree 3. Make sure to allow interactions (interaction_only=False) and set include_bias=False.\n",
    "    Store the result in 'all_x_pf'. Ensure that you make a copy of the original data and you use the scaled features ('scaled_all_x')!\n",
    "    2. Split the data ('all_x_pf') into train-val-test using proportion from 'prop_vec' and save the result as 'train_{x,y}_pf', 'val_{x,y}_pf', and 'test_{x,y}_pf'.\n",
    "    3. Train three models for comparison. \n",
    "        (a) The first is a ridge regression model 'ridge' on the original scaled data (no polynomial features) where you tuned the hyperparameters.\n",
    "        (b) The second is a linear regression model 'lr_pf' on the polynomial features data.\n",
    "        (c) The third is a regularized \"linear\" model (ridge regression) on the polynomial features data where you tuned the hyperparameters (including regularization constant ensuring alpha >= 1.0).\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "poly = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "all_x_pf = poly.fit_transform(scaled_all_x)\n",
    "\n",
    "train_x_pf, test_x_pf, train_y_pf, test_y_pf = train_test_split(all_x_pf, target_value, test_size=(prop_vec[1] + prop_vec[2]) / (prop_vec[0] + prop_vec[1] + prop_vec[2]), random_state=seed)\n",
    "test_x_pf, val_x_pf, test_y_pf, val_y_pf = train_test_split(test_x_pf, test_y_pf, test_size=(prop_vec[1] + prop_vec[2]) / (prop_vec[0]/prop_vec[1]), random_state=seed)\n",
    "\n",
    "print(\"Ridge w/o Polynomial Features:\")\n",
    "ridge_nopf = Ridge().fit(scaled_all_x, target_value)\n",
    "search_train_eval(ridge_nopf, {}, scaled_all_x, target_value, val_x, val_y)\n",
    "\n",
    "print(\"\\nLinear Regression w/ Polynomial Features:\")\n",
    "lr_pf = LinearRegression().fit(train_x_pf, train_y_pf)\n",
    "search_train_eval(lr_pf, {}, train_x_pf, train_y_pf, val_x_pf, val_y_pf)\n",
    "\n",
    "print(\"\\nRidge w/ Polynomial Features:\")\n",
    "ridge_pf = Ridge(alpha=1.0).fit(train_x_pf, train_y_pf)\n",
    "ridge_pf_params = {'alpha': [1.0, 3.0, 5.0, 7.0, 10.0]}\n",
    "ridge_pf_best_params = do_grid_search(ridge_pf, ridge_pf_params, train_x_pf, train_y_pf)\n",
    "ridge_pf_best_model = Ridge(**ridge_pf_best_params).fit(train_x_pf, train_y_pf)\n",
    "search_train_eval(ridge_pf, ridge_pf_params, train_x_pf, train_y_pf, val_x_pf, val_y_pf)\n",
    "\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a869fcd7d0c1fac1d6f305b5d52afaec",
     "grade": true,
     "grade_id": "task3a-tests",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Checks for task 3a. \"\"\"\n",
    "assert var_exists('all_x_pf') and all_x_pf.shape == (17379, 679)\n",
    "assert var_exists('train_x_pf') and var_exists('train_y_pf') and train_x_pf.shape[0] == train_y_pf.shape[0]\n",
    "assert var_exists('val_x_pf') and var_exists('val_y_pf') and val_x_pf.shape[0] == val_y_pf.shape[0]\n",
    "assert var_exists('test_x_pf') and var_exists('test_y_pf') and test_x_pf.shape[0] == test_y_pf.shape[0]\n",
    "assert train_x_pf.shape[0] == 13903 and val_x_pf.shape[0] == 1738 and test_x_pf.shape == val_x_pf.shape\n",
    "assert train_x_pf.shape[1] == val_x_pf.shape[1]\n",
    "assert np.amin(train_x_pf) >= 0.0 and np.amax(train_x_pf) <= 1.0\n",
    "\n",
    "assert var_exists('ridge_nopf') and var_exists('lr_pf') and var_exists('ridge_pf')\n",
    "assert ridge_nopf.coef_.shape == (14,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5417e88ed3d4f33f7626b96ece3e8ffe",
     "grade": false,
     "grade_id": "task3b-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### [Task 3b] (5 points) For each of the three models, print the three most important features (coef values and name). You can use 'get_feature_names_out'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6425b4f6904d3ac77fc5e34757315941",
     "grade": false,
     "grade_id": "task3b_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Model on Original Scaled Data:\n",
      "registered: 1000.6557404786477\n",
      "hour: 37.50448010500321\n",
      "workingday: -35.413610212240044\n",
      "\n",
      "Linear Regression Model on Polynomial Features Data:\n",
      "workingday^2: 393893214467.2939\n",
      "workingday^3: -234246012137.10712\n",
      "workingday: -159647202284.1828\n",
      "\n",
      "Regularized Linear Model on Polynomial Features Data:\n",
      "nsqrtc: -577.3443035350554\n",
      "registered: 544.5841731160823\n",
      "nsqrtc^3: 463.6812378197391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Put your code here (~5-7 lines).\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "feature_names_pf = poly.get_feature_names_out(input_features=col_names[:-1])\n",
    "\n",
    "models = [ridge_nopf, lr_pf, ridge_pf_best_model]\n",
    "model_names = ['Ridge Regression Model on Original Scaled Data:',\n",
    "               'Linear Regression Model on Polynomial Features Data:',\n",
    "               'Regularized Linear Model on Polynomial Features Data:']\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    print(name)\n",
    "    sorted_indices = np.argsort(np.abs(model.coef_))[::-1][:3]\n",
    "    for idx in sorted_indices:\n",
    "        print(f\"{feature_names_pf[idx]}: {model.coef_[idx]}\")\n",
    "    print()\n",
    "\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2bea6b39d98f12d1f62f27148d85ec62",
     "grade": true,
     "grade_id": "task3b_manual_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" THIS CODE CELL IS INTENTIONALLY LEFT EMPTY.  Remove the 'raise NotImplementedError' line. You should leave this cell empty (it is used for autograding). (Do not change the cell type from code to markdown.)\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" THIS CODE CELL IS INTENTIONALLY LEFT EMPTY.  Remove the 'raise NotImplementedError' line. You should leave this cell empty (it is used for autograding). (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# THIS CODE CELL IS INTENTIONALLY LEFT EMPTY --- DO NOT MODIFY THIS CELL\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c62c7836558e3b4ee481de42b4f56d24",
     "grade": false,
     "grade_id": "task3c_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 3c] (5 points) Out of the three models, which would you use and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b344b53283df484008b5ae14a68e8ae4",
     "grade": true,
     "grade_id": "task3c_manual_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer: \n",
    "# Based on the results reported, I would choose the Ridge Regression model without polynomial features\n",
    "# or added regularization. This is because each value r^2, MSE, and MAE are consistent. The\n",
    "# training values are all slightly higher than the validation, but the validation is still on par meaning\n",
    "# good generalization by the model. Also, the 3 most important features seem more relevant to one another compared \n",
    "# to the other models outputs. Plus, the models trained with polynomial features seem a bit overfitted in the \n",
    "# results they output. \n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "449dab32812541b0bb11bb3e3a649358",
     "grade": false,
     "grade_id": "task4-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [Task 4] (25 points) Trees and Bagging Ensembles!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c85c9b2327b4e739bb17ea6c2145c1d",
     "grade": false,
     "grade_id": "task4-instruct2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Let's do some cleanup and sanity checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a12e338911260c668247d0041d1c859",
     "grade": false,
     "grade_id": "task4-instruct-code",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# let's do some cleanup and discard all the polynomial features stuff.\n",
    "if var_exists('all_x_pf'):\n",
    "    del all_x_pf, train_x_pf, train_y_pf, test_x_pf, test_y_pf, val_x_pf, val_y_pf\n",
    "\n",
    "# sanity check shapes\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape, val_x.shape, val_y.shape\n",
    "assert train_x.shape == (13903, 14) and val_x.shape == (1738, 14) and test_x.shape == (1738, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e0011ce50befe631de399acb915a494",
     "grade": false,
     "grade_id": "task4a-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 4a] (5 points) Suppose a sklearn decision tree has n nodes. How many total splits does it contain? (Hint: think of it as a CS question not an ML question. Also think about edge cases (e.g., n=0).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "695bdedb230ff2cea44d95bf364ab6a2",
     "grade": false,
     "grade_id": "task4a_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Put your code here to answer by implementing the function.\n",
    "\"\"\"\n",
    "def num_dt_splits(nodes): # should return the total number of splits in a decision tree. Must return an integer value.\n",
    "    assert nodes >= 0\n",
    "    # YOUR CODE HERE\n",
    "    if nodes == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        nodes = nodes - 1\n",
    "        return nodes\n",
    "    # raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da184360d058a9471fe3344d3dc64b19",
     "grade": true,
     "grade_id": "task4a-tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 4a. \"\"\"\n",
    "assert var_exists('num_dt_splits')\n",
    "assert num_dt_splits(0) == 0 and num_dt_splits(1) == 0\n",
    "for i in range(0, 100):\n",
    "    nodes = np.random.randint(0, 1e8)\n",
    "    splits = num_dt_splits(nodes)\n",
    "    assert splits>=0 and splits == int(splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae7566934d1bdc293f09c8fb02e3e788",
     "grade": false,
     "grade_id": "cell-282724082b83b395",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Let's train a decision tree!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d562ad349530d56c05fe1c5974736c2",
     "grade": false,
     "grade_id": "task4b-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 4b] (5 points) Train and evaluate two (regression) decision trees with sklearn's DecisionTreeRegressor. The first 'dtmodel' should be trained with default parameters (set the seed). The second 'dtregmodel' should be trained with the default parameters (set the seed) but a max depth of 8. Use r2_mse_mae_eval to print performance of both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef9d31fa1e0b4b862b76d2ce94c3668f",
     "grade": false,
     "grade_id": "task4b-code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DecisionTreeRegressor]Train R^2: 1.000, Val  R^2: 0.982\n",
      "[DecisionTreeRegressor]Train MSE: 0.000, Val MSE: 545.897\n",
      "[DecisionTreeRegressor]Train MAE: 0.000, Val MAE: 8.475\n",
      "[DecisionRegTreeRegressor]Train R^2: 0.963, Val  R^2: 0.961\n",
      "[DecisionRegTreeRegressor]Train MSE: 1235.614, Val MSE: 1163.905\n",
      "[DecisionRegTreeRegressor]Train MAE: 15.622, Val MAE: 16.002\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Put your code here (~5 lines)\n",
    "\"\"\"\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# YOUR CODE HERE\n",
    "dtmodel = DecisionTreeRegressor(random_state=seed)\n",
    "dtmodel.fit(train_x, train_y)\n",
    "_ = r2_mse_mae_eval(dtmodel, train_x, train_y, val_x, val_y, pref='[DecisionTreeRegressor]')\n",
    "\n",
    "dtregmodel = DecisionTreeRegressor(max_depth=8, random_state=seed)\n",
    "dtregmodel.fit(train_x, train_y)\n",
    "_ = r2_mse_mae_eval(dtregmodel, train_x, train_y, val_x, val_y, pref='[DecisionRegTreeRegressor]')\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef804154acc025a0f2dd335fd35fc345",
     "grade": true,
     "grade_id": "task4b-checks",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 4b. \"\"\"\n",
    "assert var_exists('dtmodel') and var_exists('dtregmodel') \n",
    "assert dtmodel.tree_.max_depth >= 8 and dtregmodel.tree_.max_depth == 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9de52d5ce39f0ee93b9ea9c7ac11c9f",
     "grade": false,
     "grade_id": "task4c-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 4c] (5 points) Is the regularized model overfitted? Is it better than the models trained in Tasks 2 and 3? (A few sentences suffice.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff373393b63e44dd706dd02be10f635c",
     "grade": true,
     "grade_id": "task4c_manual_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer: \n",
    "# The regularized model is not overfitting as much as the original model. This is proven as \n",
    "# all of the metrics are around the same values with training being slightly higher except for\n",
    "# in the case of MAE. Training with deeper tree depths could fix this slight issue. The regularized\n",
    "# model is better than the models trained in Tasks 2 and 3.This is evident through MSE and MAE being lower\n",
    "# than each of the other models being compared while also still having comparable, if not higher, \n",
    "# r^2 score.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60d37ad914f87535f1c9bb16bb9526f7",
     "grade": false,
     "grade_id": "cell-fb9d19cf2516c675",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Let's explore bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e8dd970d6ffe798592d102494514539",
     "grade": false,
     "grade_id": "task4d_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 4d] (5 points) Train two ensemble models using sklearn's BaggingRegressor. Use default parameters but be sure to set the seed and set max_samples=0.5. The first ensemble 'lr_bagging' must use 'LinearRegression' as weak learners, whereas the second 'dtr_bagging' must use 'DecisionTreeRegressor' as weak learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16e5d3a3b91e41285e5e9f093eb1f03c",
     "grade": false,
     "grade_id": "task4d_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear Regression Bagging] Train R^2: -0.957, Val  R^2: 0.891\n",
      "[Linear Regression Bagging] Train MSE: 64982.388, Val MSE: 3238.971\n",
      "[Linear Regression Bagging] Train MAE: 36.519, Val MAE: 32.662\n",
      "\n",
      "[DT Regression Bagging aka Random Forest] Train R^2: 0.990, Val  R^2: 0.984\n",
      "[DT Regression Bagging aka Random Forest] Train MSE: 334.994, Val MSE: 478.150\n",
      "[DT Regression Bagging aka Random Forest] Train MAE: 5.967, Val MAE: 7.918\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Put your code here (~3 lines)\n",
    "\"\"\"\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "# YOUR CODE HERE\n",
    "lr_bagging = BaggingRegressor(estimator=LinearRegression(), random_state=seed, max_samples=0.5)\n",
    "lr_bagging.fit(train_x, train_y)\n",
    "\n",
    "dtr_bagging = BaggingRegressor(estimator=DecisionTreeRegressor(), random_state=seed, max_samples=0.5)\n",
    "dtr_bagging.fit(train_x, train_y)\n",
    "# raise NotImplementedError()\n",
    "\n",
    "_ = r2_mse_mae_eval(lr_bagging, train_x, train_y, val_x, val_y, pref='[Linear Regression Bagging] ')\n",
    "print()\n",
    "_ = r2_mse_mae_eval(dtr_bagging, train_x, train_y, val_x, val_y, pref='[DT Regression Bagging aka Random Forest] ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "527ec37234f653709a3f8c57a3febf74",
     "grade": true,
     "grade_id": "task4d_tests",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 4d. \"\"\"\n",
    "assert var_exists('lr_bagging') and var_exists('dtr_bagging') \n",
    "assert lr_bagging.random_state == dtr_bagging.random_state and dtr_bagging.random_state == seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1380de7303df21fa79e0942ecf785d86",
     "grade": false,
     "grade_id": "task4e-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 4e] (5 points) Answer the following questions: \n",
    "### 1. Is the linear regression bagging ensemble a better model than linear regression (Task 2)? Is this expected? (We are looking for an explanation of why this approach performs the way it does.)\n",
    "### 2. How does the random forest compare to all other models in this and previous task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34e515e74c59752f118ce4e0a5c383c9",
     "grade": true,
     "grade_id": "task4e_manual_answer",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Remove the 'raise NotImplementedError' line. Write your answer as a comment in the place provided.  (Do not change the cell type from code to markdown.)\"\"\"\n",
    "# \n",
    "## Answer: \n",
    "# (1) In terms of validation, the linear regression bagging ensemble model generalizes better than the \n",
    "# model from Task 2. As we can see, variance is reduced here based on the validation results, but bias\n",
    "# is high based on the training results. Bagging the models also helps avoid overfitting in the final model\n",
    "# and lower complexity yields lower variance which leads to better generalization.\n",
    "\n",
    "# (2) The random forest outperforms all of the previous models in regards to validation results. It proves\n",
    "# to have better performance overall in accuracy and generalization.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3499cc9afa0dbb2dd6b9244b3eaba066",
     "grade": false,
     "grade_id": "task5_instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "# [Task 5] \\<*For CAI6108MLE Only*\\> (25 points) Stacking & MoE. For this task you will implement a (kind of) Stacking/MoE approach. \n",
    "# Roughly speaking the approach will be to randomly choose weak learners out of a pool of candidates (determined by the *last* digit of your UFID) and train each one of a randomly selected subset of features. With the weak learners trained, we will train a gating model to learn weights to combine the weak learners' predictions into a single final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "293408be685634ca1bdd7aa55dc4c9dd",
     "grade": false,
     "grade_id": "task5_instruct2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 5] The following code is provided, you should not modify it. But you should *read* it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a99ed5b7f1a30b591f52708cf5b8b8d3",
     "grade": false,
     "grade_id": "task5_provided_code",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, LassoLars\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "\"\"\" Returns candidate weak learners based on UFID digit.\n",
    "\"\"\"\n",
    "def weak_learner_candidates(ufid_digit):\n",
    "    if ufid_digit in [1, 3, 6]:\n",
    "        return [SVR(kernel='poly'), Ridge(), DecisionTreeRegressor(max_depth=10)]\n",
    "    elif ufid_digit in [2, 4, 7]:\n",
    "        return [SVR(kernel='poly'), LassoLars(), KNeighborsRegressor(n_neighbors=3)]\n",
    "    else:\n",
    "        assert ufid_digit in [0, 5, 8, 9] \n",
    "        return [DecisionTreeRegressor(max_depth=8), Ridge(), KNeighborsRegressor(n_neighbors=1)]\n",
    "\n",
    "\"\"\" Randomly sample and return a weak learner out of the candidate pool.\n",
    "\"\"\"\n",
    "def random_weak_learner(candidates_fn):\n",
    "    assert candidates_fn is not None\n",
    "\n",
    "    candidates = candidates_fn()\n",
    "    assert len(candidates) == 3\n",
    "    ridx = np.random.randint(0, len(candidates))\n",
    "\n",
    "    return candidates[ridx]\n",
    "\n",
    "\"\"\" Predicts the value(s) on 'x' given the weak_learners and gating function. (Can you figure out how it works??)\n",
    "\"\"\"\n",
    "def predict(weak_learners, gating, x, epsilon=1e-4):\n",
    "    k = len(weak_learners)\n",
    "    \n",
    "    gating_weights = np.ones((x.shape[0], k)) * epsilon\n",
    "    gw = gating.predict_proba(x)\n",
    "    for i, cidx in enumerate(gating.classes_):\n",
    "        gating_weights[:,cidx] = gw[:,i]\n",
    "    gating_weights = gating_weights / np.sum(gating_weights, axis=-1).reshape((-1,1))\n",
    "    \n",
    "    pred_y = np.zeros((x.shape[0],))\n",
    "    for i, tup in enumerate(weak_learners):\n",
    "        weak_learner, sel_features = tup\n",
    "        predi = weak_learner.predict(x[:,sel_features])\n",
    "        pred_y += gating_weights[:,i] * predi\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8f0057245f1024a6d53c389b3486321",
     "grade": false,
     "grade_id": "task5a-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 5a] (10 points) Fill in the code of 'train_ensemble' and 'train_gating' following the provided instructions. Note: instructions do not spell out what every line of code you write should do --- that is for you to figure out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1bf9901cd611d84172e788d165f9eaba",
     "grade": false,
     "grade_id": "task5a-code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Trains the ensemble of 'num_weak_learners' of randomly chosen weak learners, each selecting a random subset of 'num_sel_features' features.\n",
    "    Returns a list of tuples composed of the trained weak learner ('weak_learner') and the chosen features ('fidx).\n",
    "\"\"\"\n",
    "def train_ensemble(tr_x, tr_y, candidates_fn, num_weak_learners=16, num_sel_features=7):\n",
    "    ret = []\n",
    "    num_features = train_x.shape[1]\n",
    "    for i in range(0, num_weak_learners):\n",
    "\n",
    "        \"\"\"Put your code here (~3-4 lines)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        weak_learner = random_weak_learner(candidates_fn)\n",
    "        fidx = np.random.choice(num_features, num_sel_features, replace=False)\n",
    "        weak_learner.fit(tr_x[:, fidx], tr_y)\n",
    "        # raise NotImplementedError()\n",
    "        \n",
    "        weak_learner_tup = (weak_learner, fidx)\n",
    "        ret.append(weak_learner_tup)\n",
    "    return ret\n",
    "\n",
    "\n",
    "\"\"\" Trains the gating function (logistic regression) using the provided list of weak learners tuples.\n",
    "    Returns the gating model, errors matrix and best weak learner idx.\n",
    "\"\"\"\n",
    "def train_gating(weak_learners, tr_x, tr_y):\n",
    "    k = len(weak_learners)\n",
    "    errors = np.ones((tr_x.shape[0], k)) * np.inf\n",
    "    \"\"\"Put your code here (~3-4 lines). For each weak learner measure its *absolute errors* on tr_{x,y} (put that in 'errors').\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    for i, (weak_learner, sel_features) in enumerate(weak_learners):\n",
    "        pred_y = weak_learner.predict(tr_x[:, sel_features])\n",
    "        errors[:, i] = np.abs(pred_y - tr_y)\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "    bestidx = np.argmin(errors, axis=-1) # compute the weak learning idx with the lowest error\n",
    "    \n",
    "    # train a logistic regression model for the gating\n",
    "    class_weight = {i:1.0 for i in range(0, k)}\n",
    "    gating = LogisticRegression(penalty='l2', C=1.0, random_state=seed, max_iter=10000, class_weight=class_weight, multi_class='multinomial')\n",
    "    gating.fit(tr_x, bestidx)\n",
    "\n",
    "    return gating, errors, bestidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51c93ac8ed11f6fa777471dc8dabdfcd",
     "grade": true,
     "grade_id": "task5a-checks",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 5a. \"\"\"\n",
    "assert var_exists('weak_learner_candidates') and var_exists('random_weak_learner') \n",
    "assert var_exists('train_gating') and var_exists('train_ensemble') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dfce67c6e346df2c380433e8ff8b63eb",
     "grade": false,
     "grade_id": "task5b-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 5b] (10 points) Fill in the provided code. Use the functions you previously implemented to train the ensemble and the gating models and make predictions on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a92c9bec3d92d5b7d18a3bc037d9534",
     "grade": false,
     "grade_id": "task5b-code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] R^2: 0.944, MSE: 1660.4, MAE: 23.1 [Elapsed: 49.1 seconds]\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "\"\"\"Put your code here (~3-4 lines). \n",
    "    1. Split the training data into s1_{x,y} and s2_{x,y} such that 70% ends up in s1 (and 30% in s2).\n",
    "    2. train the ensemble on s1_{x,y} [do not forget to use the *last* digit of your UFID].\n",
    "\"\"\"\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# YOUR CODE HERE\n",
    "s1_x, s2_x, s1_y, s2_y = train_test_split(train_x, train_y, test_size=0.3, random_state=seed)\n",
    "wls = train_ensemble(s1_x, s1_y, lambda: weak_learner_candidates(6), num_weak_learners=16, num_sel_features=7)\n",
    "# raise NotImplementedError()\n",
    "\n",
    "# train the gating on s2_{x,y}\n",
    "gating, errors, bestidx = train_gating(wls, s2_x, s2_y)\n",
    "# use the predict function to make predictions on the validation data\n",
    "pred_y = predict(wls, gating, val_x)\n",
    "\n",
    "\"\"\"Put your code here (~3-4 lines). \n",
    "    compute the R^2, MSE, MAE on the validation data (using 'pred_y') and store the result as 'val_r2', 'val_mse', 'val_mae'\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "val_r2 = r2_score(val_y, pred_y)\n",
    "val_mse = mean_squared_error(val_y, pred_y)\n",
    "val_mae = mean_absolute_error(val_y, pred_y)\n",
    "# raise NotImplementedError()\n",
    "\n",
    "et = time.time()\n",
    "elapsed = et - st\n",
    "print('[Val] R^2: {:.3f}, MSE: {:.1f}, MAE: {:.1f} [Elapsed: {:.1f} seconds]'.format(val_r2, val_mse, val_mae, elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "797a5b0af1bcbb19f897190a86dc79b9",
     "grade": true,
     "grade_id": "task5b_tests",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 5b. \"\"\"\n",
    "\n",
    "assert var_exists('gating')\n",
    "assert elapsed < 300.0\n",
    "assert np.abs(val_r2 - 0.88) <= 0.12 and np.abs(val_mae - 30) <= 30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18b847192d58dc3d9c4c4f1e993e0407",
     "grade": false,
     "grade_id": "task5c-instruct",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [Task 5c] (5 points) Now observe that 'num_weak_learners' and 'num_sel_features' in train_ensemble can be considered hyperparameters. Write some code to tune them through a simple grid search and then print the best value for them and the performance of the resulting ensemble model. (For this question best means the one with lowest val R^2.) Is it better than previous models in this homework?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0338b34208be0df1b92b0ae90fbae45a",
     "grade": false,
     "grade_id": "task5c-code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] R^2: 0.946, MSE: 1660.4, MAE: 23.1 [Best hyperparams: 8, 7]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Put your code here. Call the resulting best hyperparameters 'best_num_weak_learners' and 'best_num_sel_features'\n",
    "    Store the performance R^2, MSE, MAE as 'val_r2', 'val_mse', 'val_mae'\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "best_val_r2 = -float('inf')\n",
    "best_num_weak_learners = None\n",
    "best_num_sel_features = None\n",
    "\n",
    "nwlv = [2, 4, 8, 16, 32, 64]\n",
    "nsfv = [3, 5, 7, 9]\n",
    "\n",
    "for nwl in nwlv:\n",
    "    for nsf in nsfv:\n",
    "        wls = train_ensemble(s1_x, s1_y, lambda: weak_learner_candidates(6), num_weak_learners=nwl, num_sel_features=nsf)\n",
    "        gating, errors, bestidx = train_gating(wls, s2_x, s2_y)\n",
    "        pred_y = predict(wls, gating, val_x)\n",
    "        \n",
    "        val_r2 = r2_score(val_y, pred_y)\n",
    "        \n",
    "        if val_r2 > best_val_r2:\n",
    "            best_val_r2 = val_r2\n",
    "            best_num_weak_learners = nwl\n",
    "            best_num_sel_features = nsf\n",
    "# raise NotImplementedError()\n",
    "print('[Val] R^2: {:.3f}, MSE: {:.1f}, MAE: {:.1f} [Best hyperparams: {}, {}]'.format(val_r2, val_mse, val_mae, best_num_weak_learners, best_num_sel_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2ee25aea7b3cdffb0705fd51f663f74",
     "grade": true,
     "grade_id": "task5c-checks",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" [ASSERTS] Check task 5c. \"\"\"\n",
    "\n",
    "assert var_exists('best_num_weak_learners') and var_exists('best_num_sel_features')\n",
    "assert np.abs(val_r2 - 0.92) <= 0.08 and np.abs(val_mae - 24) <= 24\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
